{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COLLECT DISTRICT COORDINATE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "overpass_url = \"http://overpass-api.de/api/interpreter\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_roman(num):\n",
    "    # convert number to roman numbers\n",
    "    # for district queries\n",
    "    roman = OrderedDict()\n",
    "    roman[1000] = \"M\"\n",
    "    roman[900] = \"CM\"\n",
    "    roman[500] = \"D\"\n",
    "    roman[400] = \"CD\"\n",
    "    roman[100] = \"C\"\n",
    "    roman[90] = \"XC\"\n",
    "    roman[50] = \"L\"\n",
    "    roman[40] = \"XL\"\n",
    "    roman[10] = \"X\"\n",
    "    roman[9] = \"IX\"\n",
    "    roman[5] = \"V\"\n",
    "    roman[4] = \"IV\"\n",
    "    roman[1] = \"I\"\n",
    "\n",
    "    def roman_num(num):\n",
    "        for r in roman.keys():\n",
    "            x, y = divmod(num, r)\n",
    "            yield roman[r] * x\n",
    "            num -= (r * x)\n",
    "            if num <= 0:\n",
    "                break\n",
    "\n",
    "    return \"\".join([a for a in roman_num(num)])\n",
    "\n",
    "def json_loader(file):\n",
    "    # loads a json 'file' into a dictionary object\n",
    "    with open(file, 'r') as fp:\n",
    "        loaded_json = json.load(open(file))\n",
    "    return loaded_json\n",
    "\n",
    "def get_overpass_query_from_listofIDs(type_, list_of_ids):\n",
    "    # queries a list of object ids with type_ (node, way, rel)\n",
    "    return f\"\"\"\n",
    "    [out:json];\n",
    "    \"\"\" + \"(\"+\";\".join([f\"{type_}({id_})\" for id_ in list_of_ids])+\";)\" + \"\"\";\n",
    "    out center;\n",
    "    \"\"\"\n",
    "\n",
    "def get_border_of_district(ker, nodes_resp, nodes_resp_byways):\n",
    "    # get first ways coordinates in correct order\n",
    "    firstway = list(nodes_resp_byways[ker].keys())[0]\n",
    "    sorted_df = sort_points(nodes_resp_byways[ker][firstway])\n",
    "    \n",
    "    # we should not look for continuation in ways done\n",
    "    ways_done = [firstway]\n",
    "    id_to_find = sorted_df.iloc[-1]['id']\n",
    "    \n",
    "    # find the next way to continue\n",
    "    while len(ways_done) != len(nodes_resp_byways[ker].keys()):\n",
    "        next_way = find_next_way(ker, nodes_resp_byways, ways_done, id_to_find)\n",
    "        if next_way is None:\n",
    "                next_way = find_next_way_alt(ker, nodes_resp, nodes_resp_byways, ways_done, id_to_find, sorted_df)\n",
    "        sorted_df_new = sort_points(nodes_resp_byways[ker][next_way], id_to_find)\n",
    "        sorted_df = sorted_df.append(sorted_df_new, sort=False)\n",
    "        ways_done.append(next_way)\n",
    "        id_to_find = sorted_df.iloc[-1]['id']\n",
    "    \n",
    "    sorted_df['name'] = f'{ker}. kerulet'\n",
    "    return json.loads(sorted_df.reset_index(drop=True).drop(['tags', 'type', 'dist'], axis = 1, errors='ignore').to_json(orient='records'))\n",
    "\n",
    "lat = 0\n",
    "lon = 0\n",
    "\n",
    "def get_dist(row, lat = lat, lon = lon):\n",
    "    # get distance of coordinates\n",
    "    return (((row['lat'] - lat) ** 2) + ((row['lon'] - lon) ** 2)) ** 0.5\n",
    "\n",
    "def sort_points(df, id_to_start=None):\n",
    "    # sort coordinates by closeness\n",
    "    if id_to_start:\n",
    "        elso_df = pd.DataFrame(df)\n",
    "        elso_df['ordering'] = np.where(elso_df['id'] == id_to_start, 0, 1)\n",
    "        elso_df = elso_df.sort_values('ordering').reset_index(drop=True)\n",
    "        elso_df = elso_df.drop('ordering', axis = 1)\n",
    "        sorted_df = pd.DataFrame(elso_df.loc[0]).T\n",
    "    else:\n",
    "        elso_df = pd.DataFrame(df).sort_values(by = ['lon', 'lat']).reset_index(drop = True)\n",
    "        sorted_df = pd.DataFrame(elso_df.loc[0]).T\n",
    "    lat = elso_df.loc[0, 'lat']\n",
    "    lon = elso_df.loc[0, 'lon']\n",
    "    elso_df.drop(0, inplace = True)\n",
    "    \n",
    "    while len(elso_df) > 0:\n",
    "        elso_df['dist'] = elso_df.apply(lambda x: get_dist(x, lat, lon), axis = 1)\n",
    "        elso_df = elso_df.sort_values(by = 'dist')\n",
    "        sorted_df = sorted_df.append(pd.DataFrame(elso_df.loc[elso_df.index[0]]).T, sort = True)\n",
    "        lat = sorted_df.iloc[-1]['lat']\n",
    "        lon = sorted_df.iloc[-1]['lon']\n",
    "        elso_df.drop(elso_df.index[0], inplace = True)\n",
    "    \n",
    "    return sorted_df\n",
    "\n",
    "def find_next_way(ker, nodes_resp_byways, ways_done, id_to_find):\n",
    "    # find the way which is not done yet having the node \n",
    "    for way in [f for f in nodes_resp_byways[ker].keys() if not f in ways_done]:\n",
    "        for node in nodes_resp_byways[ker][way]:\n",
    "            if node['id'] == id_to_find:\n",
    "                return way\n",
    "        \n",
    "def find_next_way_alt(ker, nodes_resp, nodes_resp_byways, ways_done, id_to_find, sorted_df):\n",
    "    # find potential next points\n",
    "    available_points = [f for f in nodes_resp[ker] if not f['id'] in sorted_df['id'].tolist()]\n",
    "    \n",
    "    # calculate the closest\n",
    "    temp_df = pd.DataFrame(available_points)\n",
    "    temp_df['dist'] = temp_df.apply(lambda x: get_dist(x, sorted_df.iloc[-1]['lat'], sorted_df.iloc[-1]['lon']), axis = 1)\n",
    "    next_id = temp_df.sort_values('dist').reset_index(drop=True).loc[0, 'id']\n",
    "    \n",
    "    # return way with the closest id to continue\n",
    "    return [f for f in get_wayids_for_nodeid(next_id, ker, nodes_resp_byways) if not f in ways_done][0]\n",
    "\n",
    "def json_to_file(my_json, filename):\n",
    "    with open(filename, 'w') as fp:\n",
    "        json.dump(my_json, fp)\n",
    "        \n",
    "def get_wayids_for_nodeid(nodeid, ker, nodes_resp_byways):\n",
    "    # get ways a node is part of\n",
    "    return [f for f in nodes_resp_byways[ker].keys() if nodeid in [g['id'] for g in nodes_resp_byways[ker][f]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DISTRICTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET WAYS BORDERING DISTRICTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: I. kerület\n",
      "Success!\n",
      "Downloading: II. kerület\n",
      "Success!\n",
      "Downloading: III. kerület\n",
      "Success!\n",
      "Downloading: IV. kerület\n",
      "Error, try again...\n",
      "Success!\n",
      "Downloading: V. kerület\n",
      "Success!\n",
      "Downloading: VI. kerület\n",
      "Success!\n",
      "Downloading: VII. kerület\n",
      "Success!\n",
      "Downloading: VIII. kerület\n",
      "Success!\n",
      "Downloading: IX. kerület\n",
      "Success!\n",
      "Downloading: X. kerület\n",
      "Success!\n",
      "Downloading: XI. kerület\n",
      "Success!\n",
      "Downloading: XII. kerület\n",
      "Success!\n",
      "Downloading: XIII. kerület\n",
      "Success!\n",
      "Downloading: XIV. kerület\n",
      "Success!\n",
      "Downloading: XV. kerület\n",
      "Success!\n",
      "Downloading: XVI. kerület\n",
      "Success!\n",
      "Downloading: XVII. kerület\n",
      "Success!\n",
      "Downloading: XVIII. kerület\n",
      "Success!\n",
      "Downloading: XIX. kerület\n",
      "Success!\n",
      "Downloading: XX. kerület\n",
      "Success!\n",
      "Downloading: XXI. kerület\n",
      "Success!\n",
      "Downloading: XXII. kerület\n",
      "Success!\n",
      "Downloading: XXIII. kerület\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "responses = {ker: None for ker in [write_roman(f) for f in range(1,24)]}\n",
    "\n",
    "for ker in [write_roman(f) for f in range(1,24)]:\n",
    "    print(f\"Downloading: {ker}. kerület\")\n",
    "    overpass_query = f\"\"\"\n",
    "    [out:json];\n",
    "    area[\"ISO3166-1\"=\"HU\"][admin_level=2];\n",
    "    (\n",
    "     rel[\"name\"=\"{ker}. kerület\"](area);\n",
    "    );\n",
    "    out center;\n",
    "    \"\"\"\n",
    "\n",
    "    response = requests.get(overpass_url, params={'data': overpass_query}, headers={'User-Agent': user_agent})\n",
    "    try:\n",
    "        responses[ker] = response.json()\n",
    "        print('Success!')\n",
    "    except:\n",
    "        print('Error, try again...')\n",
    "        response = requests.get(overpass_url, params={'data': overpass_query}, headers={'User-Agent': user_agent})\n",
    "        responses[ker] = response.json()\n",
    "        print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET WAYS AND POINTS CONSTRUCTING THE DISTRICT BORDERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distill necessary information\n",
    "outer_ways = {ker: \n",
    "              [i['ref'] for i in responses[ker]['elements'][0]['members'] if i['role'] == 'outer']\n",
    "              for ker in responses.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ways for I. district...\n",
      "Success!\n",
      "Downloading ways for II. district...\n",
      "Success!\n",
      "Downloading ways for III. district...\n",
      "Success!\n",
      "Downloading ways for IV. district...\n",
      "Success!\n",
      "Downloading ways for V. district...\n",
      "Success!\n",
      "Downloading ways for VI. district...\n",
      "Success!\n",
      "Downloading ways for VII. district...\n",
      "Success!\n",
      "Downloading ways for VIII. district...\n",
      "Success!\n",
      "Downloading ways for IX. district...\n",
      "Success!\n",
      "Downloading ways for X. district...\n",
      "Success!\n",
      "Downloading ways for XI. district...\n",
      "Success!\n",
      "Downloading ways for XII. district...\n",
      "Success!\n",
      "Downloading ways for XIII. district...\n",
      "Success!\n",
      "Downloading ways for XIV. district...\n",
      "Success!\n",
      "Downloading ways for XV. district...\n",
      "Success!\n",
      "Downloading ways for XVI. district...\n",
      "Success!\n",
      "Downloading ways for XVII. district...\n",
      "Success!\n",
      "Downloading ways for XVIII. district...\n",
      "Success!\n",
      "Downloading ways for XIX. district...\n",
      "Success!\n",
      "Downloading ways for XX. district...\n",
      "Success!\n",
      "Downloading ways for XXI. district...\n",
      "Success!\n",
      "Downloading ways for XXII. district...\n",
      "Success!\n",
      "Downloading ways for XXIII. district...\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "ways_resp = {ker: None for ker in outer_ways.keys()}\n",
    "for ker in outer_ways.keys():\n",
    "    print(f\"Downloading ways for {ker}. district...\")\n",
    "    overpass_query = f\"\"\"\n",
    "        [out:json];\n",
    "         \"\"\"+ \"(\"+\";\".join([f\"way({wayid})\" for wayid in outer_ways[ker]])+\";)\" + \"\"\";\n",
    "        out center;\n",
    "        \"\"\"\n",
    "    response = requests.get(overpass_url, params={'data': overpass_query})\n",
    "    time.sleep(1)\n",
    "    try:\n",
    "        response_json = response.json()\n",
    "    except:\n",
    "        response = requests.get(overpass_url, params={'data': overpass_query}, headers={'User-Agent': user_agent})\n",
    "        response_json = response.json()\n",
    "    ways_resp[ker] = response_json\n",
    "    print('Success!')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET NODES BY DISTRICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node ids to query\n",
    "nodes_border = {ker: {i['id']: i['nodes'] for i in ways_resp[ker]['elements']} for ker in outer_ways.keys()}\n",
    "nodes_byker = {ker: [item for sublist in [list(set_) for k, set_ in nodes_border[ker].items()] for item in sublist] for ker in outer_ways.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading nodes for I. district...\n",
      "Success!\n",
      "Downloading nodes for II. district...\n",
      "Success!\n",
      "Downloading nodes for III. district...\n",
      "Success!\n",
      "Downloading nodes for IV. district...\n",
      "Success!\n",
      "Downloading nodes for V. district...\n",
      "Success!\n",
      "Downloading nodes for VI. district...\n",
      "Success!\n",
      "Downloading nodes for VII. district...\n",
      "Success!\n",
      "Downloading nodes for VIII. district...\n",
      "Success!\n",
      "Downloading nodes for IX. district...\n",
      "Success!\n",
      "Downloading nodes for X. district...\n",
      "Success!\n",
      "Downloading nodes for XI. district...\n",
      "Success!\n",
      "Downloading nodes for XII. district...\n",
      "Success!\n",
      "Downloading nodes for XIII. district...\n",
      "Success!\n",
      "Downloading nodes for XIV. district...\n",
      "Success!\n",
      "Downloading nodes for XV. district...\n",
      "Success!\n",
      "Downloading nodes for XVI. district...\n",
      "Success!\n",
      "Downloading nodes for XVII. district...\n",
      "Success!\n",
      "Downloading nodes for XVIII. district...\n",
      "Success!\n",
      "Downloading nodes for XIX. district...\n",
      "Success!\n",
      "Downloading nodes for XX. district...\n",
      "Success!\n",
      "Downloading nodes for XXI. district...\n",
      "Success!\n",
      "Downloading nodes for XXII. district...\n",
      "Success!\n",
      "Downloading nodes for XXIII. district...\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "nodes_resp = {ker: [] for ker in nodes_border.keys()}\n",
    "for ker in nodes_resp.keys():\n",
    "    print(f\"Downloading nodes for {ker}. district...\")\n",
    "    if len(nodes_byker[ker]) > 300:\n",
    "        overpass_queries = overpass_queries = [get_overpass_query_from_listofIDs('node', nodes_byker[ker][i*300:(i+1)*300]) \n",
    "                            for i in range(int(\n",
    "                                len(nodes_byker[ker])/300))] + [get_overpass_query_from_listofIDs(\n",
    "            'node', nodes_byker[ker][int(len(nodes_byker[ker])/300)*300:])]\n",
    "        responses = [requests.get(overpass_url, params={'data': overpass_query}) for overpass_query in overpass_queries]\n",
    "        try:\n",
    "            response_jsons = [response.json() for response in responses]\n",
    "        except:\n",
    "            responses = [requests.get(overpass_url, params={'data': overpass_query}) for overpass_query in overpass_queries]\n",
    "            response_jsons = [response.json() for response in responses]\n",
    "        for resp in response_jsons:    \n",
    "            nodes_resp[ker].append(resp)\n",
    "        print('Success!') \n",
    "\n",
    "    else:\n",
    "        overpass_query = get_overpass_query_from_listofIDs('node', nodes_byker[ker])\n",
    "        response = requests.get(overpass_url, params={'data': overpass_query})\n",
    "        time.sleep(1)\n",
    "        try:\n",
    "            response_json = response.json()\n",
    "        except:\n",
    "            response = requests.get(overpass_url, params={'data': overpass_query}, headers={'User-Agent': user_agent})\n",
    "            response_json = response.json()\n",
    "        nodes_resp[ker].append(response_json)\n",
    "        print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAP NODES TO WAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_resp = {ker: [item for sublist in [i['elements'] for i in nodes_resp[ker]] for item in sublist] for ker in nodes_resp.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_resp_byways = {ker: {way: [f for f in nodes_resp[ker] if f['id'] in nodes_border[ker][way]] for way in nodes_border[ker].keys()} for ker in nodes_resp.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SORT NODES USING THE ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "735bfe02db9b4fc3b1aacc8218c5c230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=23), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sorted_nodes = {ker: get_border_of_district(ker, nodes_resp, nodes_resp_byways) for ker in tqdm(nodes_resp.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create one big json list\n",
    "all_coords = []\n",
    "for ker in sorted_nodes.keys():\n",
    "    all_coords += sorted_nodes[ker]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WRITE TO FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/district_coords.txt', 'w') as fp:\n",
    "    json.dump(all_coords, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
